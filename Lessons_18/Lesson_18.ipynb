{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qYvqVign5lkZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NfZ_3V_S5s65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f94e5d95-a5af-449c-b431-758bfd2819f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Google drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aDUnKU5d5vOU"
      },
      "outputs": [],
      "source": [
        "# Setup the train and test directories\n",
        "train_dir = \"drive/MyDrive/Colab Notebooks/dataset/train/\"\n",
        "test_dir = \"drive/MyDrive/Colab Notebooks/dataset/test/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FqETdVQY6ALJ"
      },
      "outputs": [],
      "source": [
        "# Create ImageDataGenerator training instance with data augmentation\n",
        "train_datagen_augmented = ImageDataGenerator(rescale=1/255.,\n",
        "                                             rotation_range=20, # rotate the image slightly between 0 and 20 degrees\n",
        "                                             shear_range=0.2, # shear the image\n",
        "                                             zoom_range=0.2, # zoom into the image\n",
        "                                             width_shift_range=0.2, # shift the image width ways\n",
        "                                             height_shift_range=0.2, # shift the image height ways\n",
        "                                             horizontal_flip=True) # flip the image on the horizontal axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcD5OGyv6CZN",
        "outputId": "7cabd012-b54e-4540-bdf4-2c313ca19ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4500 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Import data and augment it from directories\n",
        "train_data_augmented_shuffled = train_datagen_augmented.flow_from_directory(train_dir,\n",
        "                                                                            target_size=(224, 224),\n",
        "                                                                            batch_size=32,\n",
        "                                                                            class_mode='categorical',\n",
        "                                                                            shuffle=True) # Shuffle data (default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8rHRSfyY5vCO"
      },
      "outputs": [],
      "source": [
        "# Create ImageDataGenerator test instance without data augmentation\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVgA3gdX5yI2",
        "outputId": "becc69b2-c4d6-4edc-e454-a3e6b9d1ae03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 900 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=(224, 224),\n",
        "                                             batch_size=32,\n",
        "                                             class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4xHzt1n_50Tf"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([Conv2D(filters=32, \n",
        "                                           kernel_size=3,\n",
        "                                           activation=\"relu\", \n",
        "                                           input_shape=(224, 224, 3)),\n",
        "                                    Conv2D(64, 3, activation=\"relu\"),\n",
        "                                    MaxPool2D(2),\n",
        "                                    Conv2D(128, 3, activation=\"relu\"),\n",
        "                                    MaxPool2D(2),\n",
        "                                    Conv2D(256, 3, activation=\"relu\"),\n",
        "                                    MaxPool2D(2),\n",
        "                                    Conv2D(512, 3, activation=\"relu\"),\n",
        "                                    MaxPool2D(2),\n",
        "                                    Flatten(),\n",
        "                                    Dropout(0.7),\n",
        "                                    Dense(2048, activation = 'relu'),\n",
        "                                    Dense(3, activation=\"softmax\")])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "crQZNKe656_6"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xKZbPQ459BU",
        "outputId": "15037cbf-30c1-4e08-e22f-431171d71906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 220, 220, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 110, 110, 64)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 108, 108, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 52, 52, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 24, 24, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 12, 12, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 73728)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 73728)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              150996992 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 6147      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 152,571,715\n",
            "Trainable params: 152,571,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Check out the layers in our model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd1Wngru5-4u",
        "outputId": "ddd872e9-444d-49fe-e895-c0b70ee6a9d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "141/141 [==============================] - 2378s 17s/step - loss: 1.1330 - accuracy: 0.3871 - val_loss: 0.9762 - val_accuracy: 0.5511\n",
            "Epoch 2/20\n",
            "141/141 [==============================] - 2356s 17s/step - loss: 0.9192 - accuracy: 0.5889 - val_loss: 0.7128 - val_accuracy: 0.7156\n",
            "Epoch 3/20\n",
            " 27/141 [====>.........................] - ETA: 35:01 - loss: 0.7905 - accuracy: 0.6678"
          ]
        }
      ],
      "source": [
        "# Fit the model\n",
        "history = model.fit(train_data_augmented_shuffled,\n",
        "                    epochs=20,\n",
        "                    steps_per_epoch=len(train_data_augmented_shuffled),\n",
        "                    validation_data=test_data,\n",
        "                    validation_steps=len(test_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3OENI8f6roR"
      },
      "outputs": [],
      "source": [
        "def plot_loss_curves(history):\n",
        "    \"\"\"\n",
        "    Returns separate loss curves for training and validation metrics.\n",
        "    \"\"\" \n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    epochs = range(len(history.history['loss']))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.plot(epochs, loss, label='training_loss')\n",
        "    plt.plot(epochs, val_loss, label='val_loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "    plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "    plt.title('Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT7TvsrN6sis"
      },
      "outputs": [],
      "source": [
        "# Check out the loss curves of model\n",
        "plot_loss_curves(history)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "twRPvzqxKvOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "!wget https://media-cdn.tripadvisor.com/media/photo-s/1c/d0/ba/1a/veggie-pizza.jpg\n",
        "pizza = mpimg.imread(\"veggie-pizza.jpg\")\n",
        "plt.imshow(pizza)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mFrZ9PRIKpni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of our image\n",
        "pizza.shape"
      ],
      "metadata": {
        "id": "WUGEn0n0Kshj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to import an image and resize it to be able to be used with our model\n",
        "def load_and_prep_image(filename, img_shape=224):\n",
        "    \"\"\"\n",
        "    Reads an image from filename, turns it into a tensor\n",
        "    and reshapes it to (img_shape, img_shape, colour_channel).\n",
        "    \"\"\"\n",
        "    # Read in target file (an image)\n",
        "    img = tf.io.read_file(filename)\n",
        "\n",
        "    # Decode the read file into a tensor & ensure 3 colour channels \n",
        "    # (our model is trained on images with 3 colour channels\n",
        "    # but sometimes images have 4 colour channels)\n",
        "    img = tf.image.decode_image(img, channels=3)\n",
        "\n",
        "    # Resize the image (to the same size our model was trained on)\n",
        "    img = tf.image.resize(img, size = [img_shape, img_shape])\n",
        "\n",
        "    # Rescale the image (get all values between 0 and 1)\n",
        "    img = img/255.\n",
        "    return img"
      ],
      "metadata": {
        "id": "VeUakHMqKx4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "pizza = load_and_prep_image(\"veggie-pizza.jpg\")"
      ],
      "metadata": {
        "id": "sqVdF8FFK0W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pizza"
      ],
      "metadata": {
        "id": "2X9g0K7GK089"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Although our image is in the same shape as the images our model\n",
        "# has been trained on, we're still missing a dimension.\n",
        "# The batch size becomes the first dimension.\n",
        "# So in reality, our model was trained on data\n",
        "# in the shape of (batch_size, 224, 224, 3).\n",
        "# We can fix this by adding an extra to our custom\n",
        "# image tensor using tf.expand_dims.\n",
        "\n",
        "# Add an extra axis\n",
        "print(f\"Shape before new dimension: {pizza.shape}\")\n",
        "pizza = tf.expand_dims(pizza, axis=0) # add an extra dimension at axis 0\n",
        "print(f\"Shape after new dimension: {pizza.shape}\")"
      ],
      "metadata": {
        "id": "FOkesjd3K2dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pizza"
      ],
      "metadata": {
        "id": "kYm61vtLK4KH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on custom image tensor\n",
        "prediction = model.predict(pizza)"
      ],
      "metadata": {
        "id": "oTmKF7H7K67k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "hOYi1vq2K9LU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View our example image\n",
        "!wget https://www.modular.it/wp-content/uploads/2018/03/risotto-alla-parmigiana.jpeg\n",
        "risotto = mpimg.imread(\"risotto-alla-parmigiana.jpeg\")\n",
        "plt.imshow(risotto)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6CM3wS90K-YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in and preprocess our custom image\n",
        "risotto = load_and_prep_image(\"risotto-alla-parmigiana.jpeg\")"
      ],
      "metadata": {
        "id": "qqknMfb1K_u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "risotto"
      ],
      "metadata": {
        "id": "3m2IkOZoLBoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra axis\n",
        "print(f\"Shape before new dimension: {risotto.shape}\")\n",
        "risotto = tf.expand_dims(risotto, axis=0) # add an extra dimension at axis 0\n",
        "print(f\"Shape after new dimension: {risotto.shape}\")"
      ],
      "metadata": {
        "id": "uAkFv7VjLDQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on custom image tensor\n",
        "prediction = model.predict(risotto)"
      ],
      "metadata": {
        "id": "612yi-mZLE9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction)"
      ],
      "metadata": {
        "id": "qv_iSL1GLImR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"pizza\", \"risotto\"]"
      ],
      "metadata": {
        "id": "fi8fI7RjLJwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_and_plot(model, filename, class_names):\n",
        "      \"\"\"\n",
        "      Imports an image located at filename, makes a prediction on it with\n",
        "      a trained model and plots the image with the predicted class as the title.\n",
        "      \"\"\"\n",
        "      # Import the target image and preprocess it\n",
        "      img = load_and_prep_image(filename)\n",
        "\n",
        "      # Make a prediction\n",
        "      pred = model.predict(tf.expand_dims(img, axis=0))\n",
        "\n",
        "      # Get the predicted class\n",
        "      pred_class = class_names[int(tf.round(pred)[0][0])]\n",
        "\n",
        "      # Plot the image and predicted class\n",
        "      plt.imshow(img)\n",
        "      plt.title(f\"Prediction: {pred_class}\")\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "uAZzsnMeLLHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/delish-191112-risotto-rice-0151-landscape-pf-1574723947.jpg\n",
        "food = mpimg.imread(\"delish-191112-risotto-rice-0151-landscape-pf-1574723947.jpg\")"
      ],
      "metadata": {
        "id": "htPUftAnLMmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test our model on a custom image\n",
        "pred_and_plot(model, \"delish-191112-risotto-rice-0151-landscape-pf-1574723947.jpg\", class_names)"
      ],
      "metadata": {
        "id": "CBhDfS07LPC_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Lesson_18.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}